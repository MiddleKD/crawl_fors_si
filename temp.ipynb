{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_query_file(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        query_list = [cur.replace(\"\\n\", \"\") for cur in f.readlines()]\n",
    "    return query_list\n",
    "\n",
    "def list_to_excel(data_list, output_fn):\n",
    "    # 데이터프레임 생성\n",
    "    df = pd.DataFrame([d for d in data_list if d is not None])\n",
    "\n",
    "    # 엑셀 파일로 저장\n",
    "    df.to_excel(output_fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrawlManager:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def call_driver(self, invisible=True):\n",
    "        driver_path = ChromeDriverManager().install()\n",
    "        \n",
    "        options = Options()\n",
    "        if invisible==True:\n",
    "            options.add_argument(\"--headless\")\n",
    "        service = Service(driver_path)\n",
    "        self.driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    def extract_user_id(self, text):\n",
    "\n",
    "        pattern = r\"https://in.naver.com/(\\w+)/contents\"\n",
    "        match = re.search(pattern, text)\n",
    "\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            None\n",
    "\n",
    "    def crawl_user_ids(self, url, user_ele_selector, max_retry_num=30):\n",
    "        self.driver.get(url)\n",
    "\n",
    "        last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        while True:\n",
    "\n",
    "            self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            bf_li_ct = len(self.driver.find_elements(By.TAG_NAME, \"li\"))\n",
    "            for _ in range(max_retry_num):\n",
    "                time.sleep(0.05)\n",
    "                af_li_ct = len(self.driver.find_elements(By.TAG_NAME, \"li\"))\n",
    "                if bf_li_ct != af_li_ct:\n",
    "                    break\n",
    "\n",
    "            new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "\n",
    "            last_height = new_height\n",
    "\n",
    "        user_eles = self.driver.find_elements(By.CSS_SELECTOR, user_ele_selector)\n",
    "        user_ids = [self.extract_user_id(cur.get_property(\"href\")) for cur in user_eles]\n",
    "\n",
    "        return user_ids\n",
    "\n",
    "    def kill_driver(self):\n",
    "        self.driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ele_selector = \"div.detail_box > div.title_area > a\"\n",
    "url_prefix = f\"https://search.naver.com/search.naver?ssc=tab.influencer.chl&where=influencer&sm=tab_jum&query=\"\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter.scrolledtext import ScrolledText\n",
    "import threading\n",
    "\n",
    "def log_tk(text):\n",
    "    log_text.insert(tk.END, f\"{text}\\n\")\n",
    "    log_text.update_idletasks()\n",
    "\n",
    "def crawl_data(file_path, user_ele_selector, url_prefix):\n",
    "    try:\n",
    "        max_retry_num = 30\n",
    "\n",
    "        log_tk(\"Make brower driver...\")\n",
    "        crawler = CrawlManager()\n",
    "        crawler.call_driver(invisible=True)\n",
    "        log_tk(\"Done\")\n",
    "\n",
    "        log_tk(\"Open query file...\")\n",
    "        log_tk(f\"You selected {file_path} for query list\")\n",
    "        query_list = open_query_file(file_path)\n",
    "        log_tk(\"Done\")\n",
    "\n",
    "        log_tk(\"\\nStart crawling...\\n\")\n",
    "        for query in query_list:\n",
    "            log_tk(f\"Query: {query}...\")\n",
    "            user_ids = crawler.crawl_user_ids(url=url_prefix+query,\n",
    "                                            user_ele_selector=user_ele_selector,\n",
    "                                            max_retry_num=max_retry_num)\n",
    "            log_tk(f\"It has {len(user_ids)} datas.\")\n",
    "\n",
    "            log_tk(f\"Saving {query+'_inf_list.xlsx'}\")\n",
    "            list_to_excel(user_ids, query+\"_inf_list.xlsx\")\n",
    "            log_tk(f\"{query} Done\\n\")\n",
    "\n",
    "        log_tk(\"Finish crawling\\n\")\n",
    "        \n",
    "        crawler.kill_driver()\n",
    "        del crawler\n",
    "    \n",
    "        crawl_button.config(state=tk.NORMAL)\n",
    "    except Exception as e:\n",
    "        log_tk(e)\n",
    "\n",
    "def clear_log():\n",
    "    log_text.delete(1.0, tk.END)\n",
    "\n",
    "def browse_file():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    file_entry.delete(0, tk.END)\n",
    "    file_entry.insert(0, file_path)\n",
    "\n",
    "def crawl_thread():\n",
    "    crawl_button.config(state=tk.DISABLED)\n",
    "    threading.Thread(target=lambda: crawl_data(file_entry.get(), user_ele_selector_entry.get(), url_prefix_entry.get())).start()\n",
    "\n",
    "# GUI 생성\n",
    "root = tk.Tk()\n",
    "root.title(\"Naver influencer crawler\")\n",
    "\n",
    "# 파일 경로 입력 위젯\n",
    "file_frame = tk.Frame(root)\n",
    "file_frame.pack(pady=5)\n",
    "file_label = tk.Label(file_frame, text=\"TXT path:\")\n",
    "file_label.pack(side=tk.LEFT)\n",
    "file_entry = tk.Entry(file_frame, width=50)\n",
    "file_entry.pack(side=tk.LEFT, padx=5)\n",
    "browse_button = tk.Button(file_frame, text=\"browse\", command=browse_file)\n",
    "browse_button.pack(side=tk.LEFT)\n",
    "\n",
    "# 사용자 요소 선택자 입력 위젯\n",
    "user_ele_selector_frame = tk.Frame(root)\n",
    "user_ele_selector_frame.pack(pady=5)\n",
    "user_ele_selector_label = tk.Label(user_ele_selector_frame, text=\"CSS selector:\")\n",
    "user_ele_selector_label.pack(side=tk.LEFT)\n",
    "user_ele_selector_entry = tk.Entry(user_ele_selector_frame, width=50)\n",
    "user_ele_selector_entry.insert(0, user_ele_selector)\n",
    "user_ele_selector_entry.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "# URL 접두사 입력 위젯\n",
    "url_prefix_frame = tk.Frame(root)\n",
    "url_prefix_frame.pack(pady=5)\n",
    "url_prefix_label = tk.Label(url_prefix_frame, text=\"URL prefix:\")\n",
    "url_prefix_label.pack(side=tk.LEFT)\n",
    "url_prefix_entry = tk.Entry(url_prefix_frame, width=50)\n",
    "url_prefix_entry.insert(0, url_prefix)\n",
    "url_prefix_entry.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "# 로그 표시 위젯\n",
    "log_label = tk.Label(root, text=\"Log:\")\n",
    "log_label.pack(pady=5)\n",
    "log_text = ScrolledText(root, width=60, height=15)\n",
    "log_text.pack()\n",
    "\n",
    "# 크롤링 실행 및 로그 지우기 버튼\n",
    "button_frame = tk.Frame(root)\n",
    "button_frame.pack(pady=5)\n",
    "crawl_button = tk.Button(button_frame, text=\"Run\", command=crawl_thread)\n",
    "crawl_button.pack(side=tk.LEFT)\n",
    "clear_button = tk.Button(button_frame, text=\"Clear log\", command=clear_log)\n",
    "clear_button.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kjg_ver39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
